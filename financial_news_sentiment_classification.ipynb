{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a14f96e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import emoji\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "563da9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset('zeroshot/twitter-financial-news-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16da8054",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d46c476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sardorbek/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/sardorbek/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sardorbek/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/sardorbek/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download necessary NLTK data files\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Define stop words and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a set of financial slang terms and their replacements\n",
    "financial_slang = {\n",
    "    'bullish': 'positive',\n",
    "    'bearish': 'negative',\n",
    "    'moon': 'high',\n",
    "    'bagholder': 'investor',\n",
    "    'whale': 'large investor',\n",
    "    # Add more financial slang as needed\n",
    "}\n",
    "\n",
    "def preprocess(text):\n",
    "    # Remove URLs, mentions, and hashtags\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+|@\\S+|#\\S+\", '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Replace financial slang\n",
    "    for term, replacement in financial_slang.items():\n",
    "        text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "    \n",
    "    # Tokenization with TweetTokenizer to handle emojis\n",
    "    tokenizer = TweetTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    # Replace emojis with text\n",
    "    tokens = [emoji.demojize(token) for token in tokens]\n",
    "    \n",
    "    # Lowercasing and removing stopwords\n",
    "    tokens = [word.lower() for word in tokens if word.lower() not in stop_words and word.isalpha()]\n",
    "    \n",
    "    # Lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e794eb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "train_dataset = train_dataset.map(lambda x: {'text': preprocess(x['text'])})\n",
    "test_dataset = test_dataset.map(lambda x: {'text': preprocess(x['text'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ec298cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'bynd jpmorgan reel expectation beyond meat', 'label': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f71e82e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'ally ally financial pull outlook', 'label': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceaae177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_dataset['text'])\n",
    "X_test = vectorizer.transform(test_dataset['text'])\n",
    "\n",
    "y_train = train_dataset['label']\n",
    "y_test = test_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca9e15c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "nb_predictions = nb_classifier.predict(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_classifier = LogisticRegression(max_iter=1000)\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "lr_predictions = lr_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4058ffc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Accuracy: 0.7579564489112228, Precision: 0.7994742889587583, Recall: 0.5398218797921374, F1 Score: 0.5801131885563271\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.21      0.34       347\n",
      "           1       0.77      0.43      0.55       475\n",
      "           2       0.75      0.98      0.85      1566\n",
      "\n",
      "    accuracy                           0.76      2388\n",
      "   macro avg       0.80      0.54      0.58      2388\n",
      "weighted avg       0.77      0.76      0.72      2388\n",
      "\n",
      "Logistic Regression - Accuracy: 0.7918760469011725, Precision: 0.7809560273587314, Recall: 0.6303712988936433, F1 Score: 0.6762636597708379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.40      0.52       347\n",
      "           1       0.78      0.54      0.64       475\n",
      "           2       0.80      0.96      0.87      1566\n",
      "\n",
      "    accuracy                           0.79      2388\n",
      "   macro avg       0.78      0.63      0.68      2388\n",
      "weighted avg       0.79      0.79      0.77      2388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Naive Bayes Evaluation\n",
    "nb_acc = accuracy_score(y_test, nb_predictions)\n",
    "nb_prec = precision_score(y_test, nb_predictions, average='macro')\n",
    "nb_rec = recall_score(y_test, nb_predictions, average='macro')\n",
    "nb_f1 = f1_score(y_test, nb_predictions, average='macro')\n",
    "\n",
    "print(f'Naive Bayes - Accuracy: {nb_acc}, Precision: {nb_prec}, Recall: {nb_rec}, F1 Score: {nb_f1}')\n",
    "print(classification_report(y_test, nb_predictions))\n",
    "\n",
    "# Logistic Regression Evaluation\n",
    "lr_acc = accuracy_score(y_test, lr_predictions)\n",
    "lr_prec = precision_score(y_test, lr_predictions, average='macro')\n",
    "lr_rec = recall_score(y_test, lr_predictions, average='macro')\n",
    "lr_f1 = f1_score(y_test, lr_predictions, average='macro')\n",
    "\n",
    "print(f'Logistic Regression - Accuracy: {lr_acc}, Precision: {lr_prec}, Recall: {lr_rec}, F1 Score: {lr_f1}')\n",
    "print(classification_report(y_test, lr_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2ae985",
   "metadata": {},
   "source": [
    "## Method Implementation and Rationale\n",
    "\n",
    "I decided to implement two different classifiers: Naive Bayes and Logistic Regression.\n",
    "\n",
    "These methods were chosen based on their effectiveness in handling text data and their straightforward imple- mentation. Naive Bayes: This classifier is based on Bayes’ theorem with the assumption of independence between features. It is particularly effective for text classification due to its simplicity and efficiency in high-dimensional spaces (Prabha et al., 2022). Logistic Regression: This model is a linear classifier that predicts the probability of a class label based on the logistic function. It is well-suited for binary and multiclass classification problems and can handle large feature spaces (Wiley & Pace, 2015).\n",
    "Strengths:\n",
    "• Naive Bayes: Efficient, requires minimal training data, and performs well with high-dimensional data (Prabha et al., 2022).\n",
    "• Logistic Regression: Simple, interpretable, and can capture non-linear relationships with appropri- ate feature engineering (Wiley & Pace, 2015).\n",
    "Limitations:\n",
    "• Naive Bayes: The independence assumption rarely holds true for text data, which can limit its effectiveness (Prabha et al., 2022).\n",
    "• Logistic Regression: Assumes a linear relationship between features and the log-odds of the out- come, which may not always be appropriate (Wiley & Pace, 2015).\n",
    "To prepare the text data for classification, I implemented several preprocessing steps to clean and nor- malize the text:\n",
    "1. Removing Noise: URLs, mentions, and hashtags were removed to eliminate irrelevant information.\n",
    "3\n",
    "2. Replacing Financial Slang: Specific financial terms were replaced with more general terms to standardize the language.\n",
    "3. Tokenization: We used TweetTokenizer to handle Twitter-specific formatting and emojis.\n",
    "4. Replacing Emojis with Text: Emojis were converted to text descriptions to retain their sentiment information.\n",
    "5. Lowercasing and Removing Stopwords: Standard text preprocessing steps to normalize the text.\n",
    "6. Lemmatization: Converted words to their base forms to reduce dimensionality and handle different word forms.\n",
    "Features Used:\n",
    "TF-IDF Vectorization: This technique was used to transform the text data into numerical features. By setting the maximum number of features to 5000, we captured the most significant terms in the corpus. The chosen preprocessing steps and features aimed to handle the noisy and unstructured nature of tweets, especially those related to financial news. By normalizing the text and focusing on significant terms, we expected the models to perform better in capturing the sentiment of the tweets.\n",
    "\n",
    "TF-IDF Vectorization: This technique was used to transform the text data into numerical features. By setting the maximum number of features to 5000, we captured the most significant terms in the corpus. The chosen preprocessing steps and features aimed to handle the noisy and unstructured nature of tweets, especially those related to financial news. By normalizing the text and focusing on significant terms, we expected the models to perform better in capturing the sentiment of the tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ff215a",
   "metadata": {},
   "source": [
    "## Implementation Details and Testing Procedure\n",
    "\n",
    "The dataset was loaded from the Huggingface datasets repository and split into training and test sets. The training set was used to train the models, and the test set was used to evaluate their performance.\n",
    "\n",
    "Implementation challenges:\n",
    "\n",
    "Data Augmentation Challenges: The initial implementation included synonym replacement and back translation for data augmentation. However, these methods proved time-consuming and were ultimately removed to speed up the processing.\n",
    "\n",
    "Translation API Issues: \n",
    "The use of the googletrans library for back translation caused errors due to changes in the Google Translate API, necessitating a switch to the deep-translator library. This change helped mitigate translation errors but still posed time constraints.\n",
    "\n",
    "Performance Trade-offs: \n",
    "\n",
    "Finding a balance between processing time and performance improvements was challenging. Advanced data augmentation techniques were deemed too time-intensive given the constraints.\n",
    "\n",
    "Model Performance: \n",
    "\n",
    "Handling class imbalance effectively remained a challenge, with Naive Bayes strug- gling more than Logistic Regression in this aspect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa08e9b3",
   "metadata": {},
   "source": [
    "## Evaluation, Interpretation, and Discussion of Results\n",
    "\n",
    "The Naive Bayes classifier showed decent performance but struggled with class imbalance, particularly for the bearish class. The Logistic Regression classifier performed better overall, especially for the bullish and neutral classes. The higher recall and F1 score indicate better handling of imbalanced classes.\n",
    "\n",
    "The sentiment classifier for Twitter Financial News was successfully implemented using Naive Bayes and Logistic Regression models. While both models showed reasonable performance, Logistic Regression outperformed Naive Bayes in terms of accuracy, precision, recall, and F1 score. Potential improvements were identified to further enhance the classifier’s performance, including advanced feature engineering, using transformer-based models, hyperparameter tuning, cross-validation, and thorough error analysis.\n",
    "\n",
    "Possible Areas for Improvement:\n",
    "\n",
    "Transformer-based Models: Transformer-based models such as BERT for sentiment analysis in financial texts can provide substantial improvements. These models leverage deep contextual understanding and have shown superior performance across various NLP tasks. Lengkeek and Frasincar (2023) highlight how hierarchical language models that use BERT can enhance aspect-based sentiment analysis, making them well-suited for the complex and context-sensitive nature of financial news sentiment classification. Additionally, the use of transformer-based architectures allows for capturing long-range dependencies and intricate sentiment cues that simpler models might miss.\n",
    "Cross-Validation: Implementing k-fold cross-validation can ensure that the model’s performance is robust and generalizable across different subsets of the dataset. Aghbalou et al. (2022) discuss the effectiveness of k-fold cross-validation in preventing overfitting and providing a more reliable estimate of model per- formance. This method ensures that the model is trained and evaluated on multiple splits of the data, leading to a more comprehensive understanding of its strengths and weaknesses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ef526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
